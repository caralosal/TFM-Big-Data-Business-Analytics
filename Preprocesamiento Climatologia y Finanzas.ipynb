{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de las librerías necesarias y url de la que parten los datos climatológicos\n",
    "\n",
    "El objetivo de este Notebook es crear el dataframe de predicción con las variables financieras y climatológicas.\n",
    "\n",
    "Las variables climatológicas salieron de la siguiente URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://datos.madrid.es/portal/site/egob/menuitem.c05c1f754a33a9fbe4b2e4b284f1a5a0/?vgnextoid=fa8357cec5efa610VgnVCM1000001d4a900aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD&vgnextfmt=default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "directorios = os.listdir('Data/Climatología')\n",
    "\n",
    "def read_climate_data(df, cod_magnitud, cod_estacion, magnitud):\n",
    "    \n",
    "    \"\"\"Funcion que lee los datos climáticos de un archivo csv por cada año.\n",
    "    Parametros:\n",
    "        -df: dataframe que proviene de un archivo csv con los datos climatológicos agrupados\n",
    "        -cod_magnitud: código de la magnitud que se quiera según la documentación de la página de la url anterior\n",
    "        -cod_estacion: estación de la que se quiera sacar el dato\n",
    "        -magnitud: nombre que queremos asociar a la serie temporal\n",
    "    Output:\n",
    "        - Serie temporal de la magnitud seleccionada\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filtramos por la magnitud y la estación, ya que cada magnitud tiene\n",
    "    df = df[(df.loc[:, \"MAGNITUD\"] == cod_magnitud) & (df.loc[:, \"ESTACION\"] == cod_estacion)]\n",
    "\n",
    "    # Cogemos las columnas de las horas\n",
    "    cols = [\"H01\", \"H02\", \"H03\", \"H04\", \"H05\", \"H06\", \"H07\", \"H08\",\n",
    "            \"H09\", \"H10\", \"H11\", \"H12\", \"H13\", \"H14\", \"H15\", \"H16\",\n",
    "            \"H17\", \"H18\", \"H19\", \"H20\", \"H21\", \"H22\", \"H23\", \"H24\"]\n",
    "\n",
    "    dic_cols = {}\n",
    "    for i in range(24):\n",
    "        dic_cols[cols[i]] = i\n",
    "    \n",
    "    # Filtramos el dataframe por las columnas que queremos\n",
    "    df = df[[\"ANO\", \"MES\", \"DIA\"] + cols]\n",
    "\n",
    "    # Realizamos un melt para convertir la tabla en una serie temporal con \n",
    "    df = pd.melt(df, id_vars=['ANO', 'MES', 'DIA'], value_vars=cols,\n",
    "            var_name='HORA', value_name= magnitud)\n",
    "\n",
    "    df.HORA = df.HORA.map(dic_cols)\n",
    "\n",
    "    df.loc[:, \"Fecha\"] = [datetime(df.ANO[i], df.MES[i], df.DIA[i], df.HORA[i]) for i in range(len(df))]\n",
    "    \n",
    "    # Devolvermos en la función la serie temporal de la magnitud\n",
    "    return df[[\"Fecha\", magnitud]].set_index('Fecha')\n",
    "\n",
    "# Creamos dataframes vacíos para ir incluyendo en ellos las distintas series temporales\n",
    "temperatura_grouped, humedad_grouped, precipitaciones_grouped, radiacion_grouped, velocidad_grouped = pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "for directorio in directorios:\n",
    "    df = pd.read_csv('Data/Climatología/' + directorio, sep = \";\")\n",
    "    \n",
    "    # Para cada magnitud cogemos su valor y le ponemos su nombre en la serie temporal\n",
    "    temperaturas = read_climate_data(df, 83, 58, 'Temperatura')\n",
    "    humedad_relativa = read_climate_data(df, 86, 58, 'Humedad_Relativa')\n",
    "    precipitaciones = read_climate_data(df, 89, 102, 'Precipitacion')\n",
    "    radiacion_solar = read_climate_data(df, 88, 102, 'Radiacion')\n",
    "    velocidad_viento = read_climate_data(df, 81, 102, 'Velocidad_Viento')\n",
    "    \n",
    "    # Agregamos al dataframe vacío que se creó anteriormente cada iteración de cada fichero\n",
    "    temperatura_grouped = pd.concat([temperatura_grouped, temperaturas])\n",
    "    humedad_grouped = pd.concat([humedad_grouped, humedad_relativa])\n",
    "    precipitaciones_grouped = pd.concat([precipitaciones_grouped, precipitaciones])\n",
    "    radiacion_grouped = pd.concat([radiacion_grouped, radiacion_solar])\n",
    "    velocidad_grouped = pd.concat([velocidad_grouped, velocidad_viento])\n",
    "    \n",
    "    # Ordenamos los índices\n",
    "    temperatura_grouped = temperatura_grouped.sort_index()\n",
    "    humedad_grouped = humedad_grouped.sort_index()\n",
    "    precipitaciones_grouped = precipitaciones_grouped.sort_index()\n",
    "    radiacion_grouped = radiacion_grouped.sort_index()\n",
    "    velocidad_grouped = velocidad_grouped.sort_index()\n",
    "    \n",
    "# Hay atípicos en la temperatura en el 7 y 8 de septiembre de 2021 (todas las horas a -55 grados centígrados)\n",
    "# Metemos los datos a mano porque son pocos\n",
    "\n",
    "temperatura_grouped[\"Temperatura\"][temperatura_grouped.loc[:, \"Temperatura\"] == -55] = [23.6,25.8,28.1,29. ,\n",
    "            29.9,30.3,31.6,32. ,31.2,29.9,28.5,28. ,27.7,26.2, 23.3,22.2,21.5,20.8,21.1,20.2,19. ,18.2,18.1,19.4,23.6,25.8,28.1,29.]\n",
    "\n",
    "# Creamos el dataframe climatológico. Tiene las mismas dimensiones así que podemos usar la función concat sin problema\n",
    "df_climate =  pd.concat([temperatura_grouped,\n",
    "                         humedad_grouped,\n",
    "                         precipitaciones_grouped,\n",
    "                         radiacion_grouped,\n",
    "                         velocidad_grouped],\n",
    "                        axis = 1)\n",
    "\n",
    "# Creamos lasa columnas año, mes y dia para unirla luego al dataframe financiero\n",
    "df_climate.loc[:, \"ANO\"] = df_climate.index.year\n",
    "df_climate.loc[:, \"MES\"] = df_climate.index.month\n",
    "df_climate.loc[:, \"DIA\"] = df_climate.index.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de los mínimos, máximos y spreads\n",
    "\n",
    "Al igual que se realizó con los precios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperaturas_maximas = temperatura_grouped.groupby([temperatura_grouped.index.year,\n",
    "                             temperatura_grouped.index.month,\n",
    "                             temperatura_grouped.index.day]).max()\n",
    "temperaturas_minimas = temperatura_grouped.groupby([temperatura_grouped.index.year,\n",
    "                             temperatura_grouped.index.month,\n",
    "                             temperatura_grouped.index.day]).min()\n",
    "\n",
    "spread_temperaturas = temperaturas_maximas - temperaturas_minimas\n",
    "\n",
    "temperaturas_maximas.index.names = [None, None, None]\n",
    "temperaturas_maximas.columns = ['Temperatura_max']\n",
    "temperaturas_minimas.index.names = [None, None, None]\n",
    "temperaturas_minimas.columns = ['Temperatura_min']\n",
    "spread_temperaturas.index.names = [None, None, None]\n",
    "spread_temperaturas.columns = ['Spred_temperatura']\n",
    "\n",
    "temperaturas_maximas = temperaturas_maximas.reset_index()\n",
    "temperaturas_minimas = temperaturas_minimas.reset_index()\n",
    "spread_temperaturas = spread_temperaturas.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de variables financieras\n",
    "\n",
    "Se realizará con la api de Yahoo Finance para obtener el Brent el Api2 y el IBEX35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime \n",
    "\n",
    "def read_commodities(ticker, column):\n",
    "    \n",
    "    \"\"\"Función que obtine las variables financieras de Yahoo finance:\n",
    "    Parametros:\n",
    "        -ticker: nombre del símbolo que hace referencia a la variable financiera\n",
    "        -column: nombre que se le quiere poner a la serie temporal\n",
    "    Output:\n",
    "        - Serie temporal de la variable financiera seleccionada\n",
    "    \"\"\"\n",
    "    # Vamos a obtener los valores desde 2019, ya que la variable de hueco térmico tiene esta antigüedad\n",
    "    start = datetime.datetime(2019,1,1) \n",
    "    end = datetime.datetime(2022,1,4)\n",
    "    \n",
    "    # Accedemos a la api de yahoo finance\n",
    "    df = yf.Ticker(ticker)\n",
    "    \n",
    "    # Nos quedamos con el precio de cierre\n",
    "    df = df.history(start=start, end = end)[[\"Close\"]]\n",
    "    \n",
    "    # Ponemos la serie con periodicidad diaria y rellenamos los nulos con el valor anterior (para fines de semana, se \n",
    "    # realiza así en el mercado real)\n",
    "    df = df.asfreq('D', method = 'ffill')\n",
    "    df.columns = [column]\n",
    "    \n",
    "    # Creamos las columnas año, mes y día para unirlas a las variables climatológicas\n",
    "    df.loc[:, \"ANO\"] = df.index.year\n",
    "    df.loc[:, \"MES\"] = df.index.month\n",
    "    df.loc[:, \"DIA\"] = df.index.day\n",
    "    return df\n",
    " \n",
    "brent = read_commodities(\"BZ=F\", 'Brent')\n",
    "api2 = read_commodities(\"MTF=F\", 'Api2')\n",
    "ibex = read_commodities(\"^IBEX\", 'IBEX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unión del dataframe de clima con el dataframe financiero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_climate = df_climate.reset_index().merge(temperaturas_maximas,\n",
    "                 left_on = ['ANO', 'MES', 'DIA'],\n",
    "                 right_on = ['level_0', 'level_1', 'level_2']) \\\n",
    "                .merge(temperaturas_minimas,\n",
    "                 left_on = ['ANO', 'MES', 'DIA'],\n",
    "                 right_on = ['level_0', 'level_1', 'level_2']) \\\n",
    "                .merge(spread_temperaturas,\n",
    "                 left_on = ['ANO', 'MES', 'DIA'],\n",
    "                 right_on = ['level_0', 'level_1', 'level_2']) \\\n",
    "                .merge(brent, on = ['ANO', 'MES', 'DIA']) \\\n",
    "                .merge(api2, on = ['ANO', 'MES', 'DIA']) \\\n",
    "                .merge(ibex, on = ['ANO', 'MES', 'DIA']) \\\n",
    "                .drop(columns = ['level_0_x', 'level_1_x', 'level_2_x',\n",
    "                                'level_0_y', 'level_1_y','level_2_y',\n",
    "                                'level_0', 'level_1', 'level_2',\n",
    "                                'ANO','MES','DIA']) \\\n",
    "                .set_index('Fecha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportación de los datos procesados por este notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_climate.to_csv('Data/datos_climatologicos.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
